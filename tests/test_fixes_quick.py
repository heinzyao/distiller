"""
å¿«é€Ÿæ¸¬è©¦ï¼šé©—è­‰ä¿®å¾©ä»£ç¢¼çš„åŸºæœ¬åŠŸèƒ½ï¼ˆä¸éœ€è¦ç¶²çµ¡é€£æ¥ï¼‰
"""

import sys
from pathlib import Path

# æ·»åŠ  src åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

print("=" * 60)
print("å¿«é€Ÿæ¸¬è©¦ï¼šé©—è­‰ä¿®å¾©ä»£ç¢¼")
print("=" * 60)

# æ¸¬è©¦ 1ï¼šå°å…¥æ¨¡çµ„
print("\næ¸¬è©¦ 1ï¼šå°å…¥ä¿®å¾©å¾Œçš„æ¨¡çµ„...")
try:
    from distiller.crawler import product_crawler_fixed
    from distiller.crawler import review_crawler_fixed
    print("âœ… æˆåŠŸå°å…¥æ¨¡çµ„")
except ImportError as e:
    print(f"âŒ å°å…¥å¤±æ•—: {e}")
    sys.exit(1)

# æ¸¬è©¦ 2ï¼šæª¢æŸ¥å…¨å±€é–
print("\næ¸¬è©¦ 2ï¼šæª¢æŸ¥å…¨å±€é–æ˜¯å¦å­˜åœ¨...")
if hasattr(product_crawler_fixed, 'data_lock'):
    print(f"âœ… å…¨å±€é–å·²å‰µå»º: {product_crawler_fixed.data_lock}")
else:
    print("âŒ æœªæ‰¾åˆ°å…¨å±€é–")

# æ¸¬è©¦ 3ï¼šæª¢æŸ¥é…ç½®
print("\næ¸¬è©¦ 3ï¼šæª¢æŸ¥é…ç½®...")
config = product_crawler_fixed.CONFIG
print(f"  è¶…æ™‚è¨­ç½®: {config.get('timeout')} ç§’")
print(f"  é‡è©¦æ¬¡æ•¸: {config.get('max_retries')}")
print(f"  è«‹æ±‚å»¶é²: {config.get('delay')} ç§’")
if config.get('timeout') and config.get('max_retries'):
    print("âœ… é…ç½®æ­£ç¢º")
else:
    print("âŒ é…ç½®ç¼ºå¤±")

# æ¸¬è©¦ 4ï¼šæª¢æŸ¥å‡½æ•¸ç°½å
print("\næ¸¬è©¦ 4ï¼šæª¢æŸ¥å‡½æ•¸ç°½å...")
import inspect

# æª¢æŸ¥ safe_request å‡½æ•¸
sig = inspect.signature(product_crawler_fixed.safe_request)
params = list(sig.parameters.keys())
print(f"  safe_request åƒæ•¸: {params}")
if 'timeout' in params and 'max_retries' in params:
    print("âœ… safe_request åŒ…å«è¶…æ™‚å’Œé‡è©¦åƒæ•¸")
else:
    print("âŒ safe_request åƒæ•¸ä¸å®Œæ•´")

# æª¢æŸ¥ get_user_reviews å‡½æ•¸
sig = inspect.signature(review_crawler_fixed.get_user_reviews)
return_annotation = sig.return_annotation
print(f"  get_user_reviews è¿”å›é¡å‹: {return_annotation}")
if 'List' in str(return_annotation):
    print("âœ… get_user_reviews è¿”å›åˆ—è¡¨é¡å‹")
else:
    print("âš ï¸  è¿”å›é¡å‹æœªæ¨™è¨»ï¼ˆä½†æ‡‰è©²è¿”å›åˆ—è¡¨ï¼‰")

# æ¸¬è©¦ 5ï¼šæ¸¬è©¦å‡½æ•¸èª¿ç”¨ï¼ˆä½¿ç”¨ç©ºåˆ—è¡¨ï¼‰
print("\næ¸¬è©¦ 5ï¼šæ¸¬è©¦å‡½æ•¸èª¿ç”¨ï¼ˆç©ºåˆ—è¡¨ï¼‰...")
try:
    # æ¸¬è©¦ç”¢å“çˆ¬èŸ²
    product_crawler_fixed.data = []
    product_crawler_fixed.exec_count = 0
    result = product_crawler_fixed.data
    print(f"  ç”¢å“æ•¸æ“šåˆå§‹åŒ–: {len(result)} é …")

    # æ¸¬è©¦è©•è«–çˆ¬èŸ²
    reviews = review_crawler_fixed.get_user_reviews([], 0, 0)
    print(f"  è©•è«–æ•¸æ“š: {type(reviews)}, é•·åº¦: {len(reviews)}")

    if isinstance(reviews, list):
        print("âœ… å‡½æ•¸èª¿ç”¨æˆåŠŸï¼Œè¿”å›é¡å‹æ­£ç¢º")
    else:
        print(f"âŒ è¿”å›é¡å‹éŒ¯èª¤: {type(reviews)}")

except Exception as e:
    print(f"âŒ å‡½æ•¸èª¿ç”¨å¤±æ•—: {e}")

# æ¸¬è©¦ 6ï¼šé©—è­‰éŒ¯èª¤è™•ç†
print("\næ¸¬è©¦ 6ï¼šé©—è­‰éŒ¯èª¤è™•ç†...")
try:
    # æ¸¬è©¦ä¸å­˜åœ¨çš„ URLï¼ˆä¸æœƒçœŸæ­£è«‹æ±‚ï¼‰
    response = product_crawler_fixed.extract_spirit_info("invalid-url")
    print(f"  è™•ç†ç„¡æ•ˆ URL çµæœ: {response}")
    if response is None:
        print("âœ… éŒ¯èª¤è™•ç†æ­£ç¢ºï¼ˆè¿”å› Noneï¼‰")
    else:
        print("âš ï¸  éŒ¯èª¤è™•ç†å¯èƒ½æœ‰å•é¡Œ")
except Exception as e:
    print(f"  æ•ç²ç•°å¸¸: {e}")
    print("âœ… ç•°å¸¸è™•ç†æ­£å¸¸")

# ç¸½çµ
print("\n" + "=" * 60)
print("å¿«é€Ÿæ¸¬è©¦å®Œæˆï¼")
print("=" * 60)
print("\nä¸»è¦ä¿®å¾©å·²é©—è­‰ï¼š")
print("  1. âœ… å…¨å±€é–å·²å‰µå»ºï¼ˆä¿®å¾©å•é¡Œ 1ï¼‰")
print("  2. âœ… é…ç½®åŒ…å«é‡è©¦é™åˆ¶ï¼ˆä¿®å¾©å•é¡Œ 2ï¼‰")
print("  3. âœ… å‡½æ•¸è¿”å›åˆ—è¡¨é¡å‹ï¼ˆä¿®å¾©å•é¡Œ 3ï¼‰")
print("  4. âœ… é…ç½®åŒ…å«è¶…æ™‚è¨­ç½®ï¼ˆä¿®å¾©å•é¡Œ 4ï¼‰")
print("\nğŸ’¡ è¦é€²è¡Œå®Œæ•´æ¸¬è©¦ï¼ˆåŒ…å«ç¶²çµ¡è«‹æ±‚ï¼‰ï¼Œè«‹é‹è¡Œï¼š")
print("   python tests/test_crawler_fixes.py")
